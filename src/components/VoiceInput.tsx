/**
 * è¯­éŸ³è¾“å…¥ç»„ä»¶
 */

import { useState, useEffect, useRef } from 'react'
import { Button } from '@/components/ui/button'
import { Card, CardContent } from '@/components/ui/card'

interface VoiceInputProps {
  onTranscript: (text: string) => void
  disabled?: boolean
}

// è¯­éŸ³è¯†åˆ«ç±»å‹å®šä¹‰
interface SpeechRecognitionType {
  continuous: boolean
  interimResults: boolean
  lang: string
  onstart: (() => void) | null
  onresult: ((event: any) => void) | null
  onerror: ((event: any) => void) | null
  onend: (() => void) | null
  start: () => void
  stop: () => void
}

export function VoiceInput({ onTranscript, disabled = false }: VoiceInputProps) {
  const [isListening, setIsListening] = useState(false)
  const [isSupported, setIsSupported] = useState(false)
  const recognitionRef = useRef<SpeechRecognitionType | null>(null)

  useEffect(() => {
    // æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒè¯­éŸ³è¯†åˆ«
    const SpeechRecognition = 
      (window as any).SpeechRecognition || 
      (window as any).webkitSpeechRecognition

    if (SpeechRecognition) {
      setIsSupported(true)
      const recognition = new SpeechRecognition()
      recognition.continuous = false
      recognition.interimResults = false
      recognition.lang = 'zh-CN'

      recognition.onstart = () => {
        setIsListening(true)
      }

      recognition.onresult = (event: any) => {
        const transcript = Array.from(event.results || [])
          .map((result: any) => result[0]?.transcript || '')
          .join('')
        if (transcript) {
          onTranscript(transcript)
        }
      }

      recognition.onerror = (event: any) => {
        console.error('è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error)
        setIsListening(false)
        // æŸäº›é”™è¯¯ä¸éœ€è¦åœæ­¢è¯†åˆ«
        if (event.error !== 'no-speech' && event.error !== 'aborted') {
          recognitionRef.current = null
        }
      }

      recognition.onend = () => {
        setIsListening(false)
      }

      recognitionRef.current = recognition
    }

    return () => {
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop()
        } catch (e) {
          // å¿½ç•¥åœæ­¢æ—¶çš„é”™è¯¯
        }
      }
    }
  }, [onTranscript])

  const handleToggleListening = () => {
    if (!recognitionRef.current) return

    if (isListening) {
      recognitionRef.current.stop()
    } else {
      try {
        recognitionRef.current.start()
      } catch (error) {
        console.error('å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', error)
      }
    }
  }

  if (!isSupported) {
    return (
      <Card>
        <CardContent className="pt-4">
          <p className="text-sm text-muted-foreground text-center">
            æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¾“å…¥åŠŸèƒ½
            <br />
            <span className="text-xs">å»ºè®®ä½¿ç”¨ Chrome æˆ– Edge æµè§ˆå™¨</span>
          </p>
        </CardContent>
      </Card>
    )
  }

  return (
    <Button
      type="button"
      variant={isListening ? "default" : "outline"}
      onClick={handleToggleListening}
      disabled={disabled}
      className="w-full"
    >
      {isListening ? (
        <>
          <span className="mr-2">ğŸ¤</span>
          æ­£åœ¨è†å¬...
        </>
      ) : (
        <>
          <span className="mr-2">ğŸ¤</span>
          è¯­éŸ³è¾“å…¥
        </>
      )}
    </Button>
  )
}

// æ‰©å±• Window æ¥å£ä»¥æ”¯æŒè¯­éŸ³è¯†åˆ«
declare global {
  interface Window {
    SpeechRecognition?: any
    webkitSpeechRecognition?: any
  }
}

